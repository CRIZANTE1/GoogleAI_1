{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDEExiAk4fLb"
      },
      "source": [
        "# Finetune G_mini models in Keras using LoRA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFWzQEqNosrS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemma/docs/lora_tuning\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335\"><img src=\"https://ai.google.dev/images/cloud-icon.svg\" width=\"40\" />Open in Vertex AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSGRSsRPgkzK"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Adapt Large Language Models (LLMs) like G_mini to perform specific tasks by fine-tuning them with domain-specific data. However, due to the large number of model parameters in these models, full fine-tuning which updates all the model parameters is mostly infeasible due to high GPU memory requirements.\n",
        "\n",
        "[Low Rank Adaptation (LoRA)](https://arxiv.org/abs/2106.09685){:external} is a fine-tuning technique which greatly reduces the number of trainable parameters for downstream tasks by freezing the weights of the model and inserting a smaller number of new weights into the model. This makes training with LoRA much faster, memory-efficient, and produces smaller model weights (a few hundred MBs).\n",
        "\n",
        "This tutorial walks you through using Keras NLP to perform LoRA fine-tuning on a G_mini model using the [IMDb dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1q6-W_mKIT-"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHs7wpZusEML"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rly3MU4RLBp3"
      },
      "source": [
        "Set environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZdLNgBiLF2y"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZs8XXqUKRmi"
      },
      "source": [
        "Install Keras and Keras NLP with the Gemma model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eeBtYqJsZPG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.3 [5,716 B]\n",
            "Fetched 2,473 kB in 1s (1,878 kB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 121730 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.3_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.3) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.3) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'keras-nlp-g-mini'...\n",
            "remote: Enumerating objects: 9760, done.\u001b[K\n",
            "remote: Counting objects: 100% (1007/1007), done.\u001b[K\n",
            "remote: Compressing objects: 100% (338/338), done.\u001b[K\n",
            "remote: Total 9760 (delta 727), reused 905 (delta 664), pack-reused 8753\u001b[K\n",
            "Receiving objects: 100% (9760/9760), 3.94 MiB | 16.54 MiB/s, done.\n",
            "Resolving deltas: 100% (7642/7642), done.\n",
            "...processing keras_nlp/src/conftest.py\n",
            "...processing keras_nlp/src/api_export.py\n",
            "...processing keras_nlp/src/__init__.py\n",
            "...processing keras_nlp/src/version_utils.py\n",
            "...processing keras_nlp/src/tests/test_case.py\n",
            "...processing keras_nlp/src/tests/__init__.py\n",
            "...processing keras_nlp/src/layers/__init__.py\n",
            "...processing keras_nlp/src/layers/preprocessing/start_end_packer.py\n",
            "...processing keras_nlp/src/layers/preprocessing/__init__.py\n",
            "...processing keras_nlp/src/layers/preprocessing/multi_segment_packer.py\n",
            "...processing keras_nlp/src/layers/preprocessing/masked_lm_mask_generator.py\n",
            "...processing keras_nlp/src/layers/preprocessing/preprocessing_layer.py\n",
            "...processing keras_nlp/src/layers/preprocessing/random_deletion.py\n",
            "...processing keras_nlp/src/layers/preprocessing/random_swap.py\n",
            "...processing keras_nlp/src/layers/modeling/transformer_layer_utils.py\n",
            "...processing keras_nlp/src/layers/modeling/masked_lm_head.py\n",
            "...processing keras_nlp/src/layers/modeling/transformer_decoder.py\n",
            "...processing keras_nlp/src/layers/modeling/__init__.py\n",
            "...processing keras_nlp/src/layers/modeling/transformer_encoder.py\n",
            "...processing keras_nlp/src/layers/modeling/sine_position_encoding.py\n",
            "...processing keras_nlp/src/layers/modeling/position_embedding.py\n",
            "...processing keras_nlp/src/layers/modeling/cached_multi_head_attention.py\n",
            "...processing keras_nlp/src/layers/modeling/rotary_embedding.py\n",
            "...processing keras_nlp/src/layers/modeling/f_net_encoder.py\n",
            "...processing keras_nlp/src/layers/modeling/reversible_embedding.py\n",
            "...processing keras_nlp/src/layers/modeling/token_and_position_embedding.py\n",
            "...processing keras_nlp/src/metrics/edit_distance.py\n",
            "...processing keras_nlp/src/metrics/rouge_n.py\n",
            "...processing keras_nlp/src/metrics/rouge_base.py\n",
            "...processing keras_nlp/src/metrics/__init__.py\n",
            "...processing keras_nlp/src/metrics/bleu.py\n",
            "...processing keras_nlp/src/metrics/rouge_l.py\n",
            "...processing keras_nlp/src/metrics/perplexity.py\n",
            "...processing keras_nlp/src/samplers/__init__.py\n",
            "...processing keras_nlp/src/samplers/random_sampler.py\n",
            "...processing keras_nlp/src/samplers/serialization.py\n",
            "...processing keras_nlp/src/samplers/greedy_sampler.py\n",
            "...processing keras_nlp/src/samplers/sampler.py\n",
            "...processing keras_nlp/src/samplers/top_p_sampler.py\n",
            "...processing keras_nlp/src/samplers/beam_sampler.py\n",
            "...processing keras_nlp/src/samplers/contrastive_sampler.py\n",
            "...processing keras_nlp/src/samplers/top_k_sampler.py\n",
            "...processing keras_nlp/src/tokenizers/word_piece_tokenizer_trainer.py\n",
            "...processing keras_nlp/src/tokenizers/byte_pair_tokenizer.py\n",
            "...processing keras_nlp/src/tokenizers/__init__.py\n",
            "...processing keras_nlp/src/tokenizers/tokenizer.py\n",
            "...processing keras_nlp/src/tokenizers/byte_tokenizer.py\n",
            "...processing keras_nlp/src/tokenizers/word_piece_tokenizer.py\n",
            "...processing keras_nlp/src/tokenizers/sentence_piece_tokenizer.py\n",
            "...processing keras_nlp/src/tokenizers/unicode_codepoint_tokenizer.py\n",
            "...processing keras_nlp/src/tokenizers/sentence_piece_tokenizer_trainer.py\n",
            "...processing keras_nlp/src/utils/__init__.py\n",
            "...processing keras_nlp/src/utils/keras_utils.py\n",
            "...processing keras_nlp/src/utils/pipeline_model.py\n",
            "...processing keras_nlp/src/utils/tensor_utils.py\n",
            "...processing keras_nlp/src/utils/python_utils.py\n",
            "...processing keras_nlp/src/utils/preset_utils.py\n",
            "...processing keras_nlp/src/backend/random.py\n",
            "...processing keras_nlp/src/backend/__init__.py\n",
            "...processing keras_nlp/src/backend/keras.py\n",
            "...processing keras_nlp/src/backend/ops.py\n",
            "...processing keras_nlp/src/backend/config.py\n",
            "...processing keras_nlp/src/models/preprocessor.py\n",
            "...processing keras_nlp/src/models/__init__.py\n",
            "...processing keras_nlp/src/models/task.py\n",
            "...processing keras_nlp/src/models/generative_task.py\n",
            "...processing keras_nlp/src/models/backbone.py\n",
            "...processing keras_nlp/src/models/llama/llama_attention.py\n",
            "...processing keras_nlp/src/models/llama/__init__.py\n",
            "...processing keras_nlp/src/models/llama/llama_backbone.py\n",
            "...processing keras_nlp/src/models/llama/llama_tokenizer.py\n",
            "...processing keras_nlp/src/models/llama/llama_layernorm.py\n",
            "...processing keras_nlp/src/models/llama/llama_decoder.py\n",
            "...processing keras_nlp/src/models/gpt2/gpt2_presets.py\n",
            "...processing keras_nlp/src/models/gpt2/__init__.py\n",
            "...processing keras_nlp/src/models/gpt2/gpt2_backbone.py\n",
            "...processing keras_nlp/src/models/gpt2/gpt2_preprocessor.py\n",
            "...processing keras_nlp/src/models/gpt2/gpt2_causal_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/gpt2/gpt2_causal_lm.py\n",
            "...processing keras_nlp/src/models/gpt2/gpt2_tokenizer.py\n",
            "...processing keras_nlp/src/models/xlm_roberta/xlm_roberta_preprocessor.py\n",
            "...processing keras_nlp/src/models/xlm_roberta/__init__.py\n",
            "...processing keras_nlp/src/models/xlm_roberta/xlm_roberta_classifier.py\n",
            "...processing keras_nlp/src/models/xlm_roberta/xlm_roberta_presets.py\n",
            "...processing keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/xlm_roberta/xlm_roberta_tokenizer.py\n",
            "...processing keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm.py\n",
            "...processing keras_nlp/src/models/xlm_roberta/xlm_roberta_backbone.py\n",
            "...processing keras_nlp/src/models/gpt_neo_x/gpt_neo_x_decoder.py\n",
            "...processing keras_nlp/src/models/gpt_neo_x/__init__.py\n",
            "...processing keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/gpt_neo_x/gpt_neo_x_attention.py\n",
            "...processing keras_nlp/src/models/gpt_neo_x/gpt_neo_x_preprocessor.py\n",
            "...processing keras_nlp/src/models/gpt_neo_x/gpt_neo_x_backbone.py\n",
            "...processing keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm.py\n",
            "...processing keras_nlp/src/models/gpt_neo_x/gpt_neo_x_tokenizer.py\n",
            "...processing keras_nlp/src/models/xlnet/__init__.py\n",
            "...processing keras_nlp/src/models/xlnet/relative_attention.py\n",
            "...processing keras_nlp/src/models/xlnet/xlnet_backbone.py\n",
            "...processing keras_nlp/src/models/xlnet/xlnet_content_and_query_embedding.py\n",
            "...processing keras_nlp/src/models/xlnet/xlnet_encoder.py\n",
            "...processing keras_nlp/src/models/bart/bart_tokenizer.py\n",
            "...processing keras_nlp/src/models/bart/bart_presets.py\n",
            "...processing keras_nlp/src/models/bart/bart_preprocessor.py\n",
            "...processing keras_nlp/src/models/bart/__init__.py\n",
            "...processing keras_nlp/src/models/bart/bart_backbone.py\n",
            "...processing keras_nlp/src/models/bart/bart_seq_2_seq_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/bart/bart_seq_2_seq_lm.py\n",
            "...processing keras_nlp/src/models/bert/__init__.py\n",
            "...processing keras_nlp/src/models/bert/bert_classifier.py\n",
            "...processing keras_nlp/src/models/bert/bert_masked_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/bert/bert_preprocessor.py\n",
            "...processing keras_nlp/src/models/bert/bert_presets.py\n",
            "...processing keras_nlp/src/models/bert/bert_backbone.py\n",
            "...processing keras_nlp/src/models/bert/bert_masked_lm.py\n",
            "...processing keras_nlp/src/models/bert/bert_tokenizer.py\n",
            "...processing keras_nlp/src/models/bloom/bloom_attention.py\n",
            "...processing keras_nlp/src/models/bloom/__init__.py\n",
            "...processing keras_nlp/src/models/bloom/bloom_decoder.py\n",
            "...processing keras_nlp/src/models/bloom/bloom_backbone.py\n",
            "...processing keras_nlp/src/models/opt/opt_causal_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/opt/opt_preprocessor.py\n",
            "...processing keras_nlp/src/models/opt/opt_backbone.py\n",
            "...processing keras_nlp/src/models/opt/opt_tokenizer.py\n",
            "...processing keras_nlp/src/models/opt/opt_presets.py\n",
            "...processing keras_nlp/src/models/opt/__init__.py\n",
            "...processing keras_nlp/src/models/opt/opt_causal_lm.py\n",
            "...processing keras_nlp/src/models/distil_bert/distil_bert_masked_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/distil_bert/distil_bert_backbone.py\n",
            "...processing keras_nlp/src/models/distil_bert/__init__.py\n",
            "...processing keras_nlp/src/models/distil_bert/distil_bert_masked_lm.py\n",
            "...processing keras_nlp/src/models/distil_bert/distil_bert_classifier.py\n",
            "...processing keras_nlp/src/models/distil_bert/distil_bert_preprocessor.py\n",
            "...processing keras_nlp/src/models/distil_bert/distil_bert_presets.py\n",
            "...processing keras_nlp/src/models/distil_bert/distil_bert_tokenizer.py\n",
            "...processing keras_nlp/src/models/whisper/whisper_tokenizer.py\n",
            "...processing keras_nlp/src/models/whisper/whisper_cached_multi_head_attention.py\n",
            "...processing keras_nlp/src/models/whisper/whisper_preprocessor.py\n",
            "...processing keras_nlp/src/models/whisper/whisper_encoder.py\n",
            "...processing keras_nlp/src/models/whisper/__init__.py\n",
            "...processing keras_nlp/src/models/whisper/whisper_backbone.py\n",
            "...processing keras_nlp/src/models/whisper/whisper_audio_feature_extractor.py\n",
            "...processing keras_nlp/src/models/whisper/whisper_presets.py\n",
            "...processing keras_nlp/src/models/whisper/whisper_decoder.py\n",
            "...processing keras_nlp/src/models/albert/albert_masked_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/albert/albert_backbone.py\n",
            "...processing keras_nlp/src/models/albert/__init__.py\n",
            "...processing keras_nlp/src/models/albert/albert_tokenizer.py\n",
            "...processing keras_nlp/src/models/albert/albert_masked_lm.py\n",
            "...processing keras_nlp/src/models/albert/albert_classifier.py\n",
            "...processing keras_nlp/src/models/albert/albert_preprocessor.py\n",
            "...processing keras_nlp/src/models/albert/albert_presets.py\n",
            "...processing keras_nlp/src/models/g_mini/g_mini_causal_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/g_mini/g_mini_preprocessor.py\n",
            "...processing keras_nlp/src/models/g_mini/g_mini_tokenizer.py\n",
            "...processing keras_nlp/src/models/g_mini/g_mini_backbone.py\n",
            "...processing keras_nlp/src/models/g_mini/g_mini_decoder_block.py\n",
            "...processing keras_nlp/src/models/g_mini/__init__.py\n",
            "...processing keras_nlp/src/models/g_mini/g_mini_presets.py\n",
            "...processing keras_nlp/src/models/g_mini/g_mini_attention.py\n",
            "...processing keras_nlp/src/models/g_mini/rms_normalization.py\n",
            "...processing keras_nlp/src/models/g_mini/g_mini_causal_lm.py\n",
            "...processing keras_nlp/src/models/deberta_v3/disentangled_attention_encoder.py\n",
            "...processing keras_nlp/src/models/deberta_v3/__init__.py\n",
            "...processing keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm.py\n",
            "...processing keras_nlp/src/models/deberta_v3/deberta_v3_classifier.py\n",
            "...processing keras_nlp/src/models/deberta_v3/disentangled_self_attention.py\n",
            "...processing keras_nlp/src/models/deberta_v3/deberta_v3_presets.py\n",
            "...processing keras_nlp/src/models/deberta_v3/deberta_v3_preprocessor.py\n",
            "...processing keras_nlp/src/models/deberta_v3/deberta_v3_backbone.py\n",
            "...processing keras_nlp/src/models/deberta_v3/relative_embedding.py\n",
            "...processing keras_nlp/src/models/deberta_v3/deberta_v3_tokenizer.py\n",
            "...processing keras_nlp/src/models/electra/__init__.py\n",
            "...processing keras_nlp/src/models/electra/electra_tokenizer.py\n",
            "...processing keras_nlp/src/models/electra/electra_backbone.py\n",
            "...processing keras_nlp/src/models/mistral/mistral_backbone.py\n",
            "...processing keras_nlp/src/models/mistral/mistral_transformer_decoder.py\n",
            "...processing keras_nlp/src/models/mistral/mistral_preprocessor.py\n",
            "...processing keras_nlp/src/models/mistral/mistral_tokenizer.py\n",
            "...processing keras_nlp/src/models/mistral/__init__.py\n",
            "...processing keras_nlp/src/models/mistral/mistral_layer_norm.py\n",
            "...processing keras_nlp/src/models/mistral/mistral_attention.py\n",
            "...processing keras_nlp/src/models/f_net/f_net_masked_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/f_net/f_net_classifier.py\n",
            "...processing keras_nlp/src/models/f_net/__init__.py\n",
            "...processing keras_nlp/src/models/f_net/f_net_masked_lm.py\n",
            "...processing keras_nlp/src/models/f_net/f_net_preprocessor.py\n",
            "...processing keras_nlp/src/models/f_net/f_net_backbone.py\n",
            "...processing keras_nlp/src/models/f_net/f_net_presets.py\n",
            "...processing keras_nlp/src/models/f_net/f_net_tokenizer.py\n",
            "...processing keras_nlp/src/models/roberta/roberta_masked_lm_preprocessor.py\n",
            "...processing keras_nlp/src/models/roberta/__init__.py\n",
            "...processing keras_nlp/src/models/roberta/roberta_tokenizer.py\n",
            "...processing keras_nlp/src/models/roberta/roberta_masked_lm.py\n",
            "...processing keras_nlp/src/models/roberta/roberta_backbone.py\n",
            "...processing keras_nlp/src/models/roberta/roberta_presets.py\n",
            "...processing keras_nlp/src/models/roberta/roberta_classifier.py\n",
            "...processing keras_nlp/src/models/roberta/roberta_preprocessor.py\n",
            "...processing keras_nlp/src/models/t5/t5_presets.py\n",
            "...processing keras_nlp/src/models/t5/t5_layer_norm.py\n",
            "...processing keras_nlp/src/models/t5/__init__.py\n",
            "...processing keras_nlp/src/models/t5/t5_backbone.py\n",
            "...processing keras_nlp/src/models/t5/t5_tokenizer.py\n",
            "...processing keras_nlp/src/models/t5/t5_multi_head_attention.py\n",
            "...processing keras_nlp/src/models/t5/t5_transformer_layer.py\n",
            "Generating files for package 'keras_nlp' from sources found in 'keras_nlp/src'.\n",
            "2024-02-02 17:29:14.357582: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 17:29:14.357636: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 17:29:14.359448: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-02 17:29:14.367923: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-02 17:29:15.451758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using TensorFlow backend\n",
            "Compiling list of symbols to export.\n",
            "...processing symbol 'BartSeq2SeqLMPreprocessor'\n",
            "...processing symbol 'OPTPreprocessor'\n",
            "...processing symbol 'DebertaV3Backbone'\n",
            "...processing symbol 'ByteTokenizer'\n",
            "...processing symbol 'AlbertClassifier'\n",
            "...processing symbol 'MistralTokenizer'\n",
            "...processing symbol 'BartTokenizer'\n",
            "...processing symbol 'AlbertPreprocessor'\n",
            "...processing symbol 'DebertaV3Classifier'\n",
            "...processing symbol 'StartEndPacker'\n",
            "...processing symbol 'RandomSwap'\n",
            "...processing symbol 'FNetMaskedLM'\n",
            "...processing symbol 'RandomSampler'\n",
            "...processing symbol 'FNetBackbone'\n",
            "...processing symbol 'TransformerDecoder'\n",
            "...processing symbol 'XLMRobertaPreprocessor'\n",
            "...processing symbol 'GreedySampler'\n",
            "...processing symbol 'RougeL'\n",
            "...processing symbol 'WhisperTokenizer'\n",
            "...processing symbol 'FNetClassifier'\n",
            "...processing symbol 'DebertaV3Preprocessor'\n",
            "...processing symbol 'DistilBertPreprocessor'\n",
            "...processing symbol 'FNetPreprocessor'\n",
            "...processing symbol 'SentencePieceTokenizer'\n",
            "...processing symbol 'OPTCausalLMPreprocessor'\n",
            "...processing symbol 'DebertaV3MaskedLMPreprocessor'\n",
            "...processing symbol 'DistilBertTokenizer'\n",
            "...processing symbol 'FNetEncoder'\n",
            "...processing symbol 'version'\n",
            "...processing symbol 'GPTNeoXBackbone'\n",
            "...processing symbol 'GMiniTokenizer'\n",
            "...processing symbol 'GMiniCausalLMPreprocessor'\n",
            "...processing symbol 'WhisperPreprocessor'\n",
            "...processing symbol 'LlamaBackbone'\n",
            "...processing symbol 'DistilBertMaskedLMPreprocessor'\n",
            "...processing symbol 'GMiniPreprocessor'\n",
            "...processing symbol 'XLMRobertaMaskedLM'\n",
            "...processing symbol 'MistralBackbone'\n",
            "...processing symbol 'BertPreprocessor'\n",
            "...processing symbol 'BartBackbone'\n",
            "...processing symbol 'GPT2Preprocessor'\n",
            "...processing symbol 'GPTNeoXPreprocessor'\n",
            "...processing symbol 'DistilBertClassifier'\n",
            "...processing symbol 'serialize'\n",
            "...processing symbol 'DebertaV3Tokenizer'\n",
            "...processing symbol 'deserialize'\n",
            "...processing symbol 'TopPSampler'\n",
            "...processing symbol 'WhisperAudioFeatureExtractor'\n",
            "...processing symbol 'T5Backbone'\n",
            "...processing symbol 'GMiniCausalLM'\n",
            "...processing symbol 'DebertaV3MaskedLM'\n",
            "...processing symbol 'SinePositionEncoding'\n",
            "...processing symbol 'XLMRobertaBackbone'\n",
            "...processing symbol 'Sampler'\n",
            "...processing symbol 'DistilBertBackbone'\n",
            "...processing symbol 'get'\n",
            "...processing symbol 'compute_word_piece_vocabulary'\n",
            "...processing symbol 'XLMRobertaTokenizer'\n",
            "...processing symbol 'RobertaMaskedLMPreprocessor'\n",
            "...processing symbol 'FNetMaskedLMPreprocessor'\n",
            "...processing symbol 'AlbertMaskedLMPreprocessor'\n",
            "...processing symbol 'BertMaskedLM'\n",
            "...processing symbol 'BertClassifier'\n",
            "...processing symbol 'BytePairTokenizer'\n",
            "...processing symbol 'TokenAndPositionEmbedding'\n",
            "...processing symbol 'WordPieceTokenizer'\n",
            "...processing symbol 'ReversibleEmbedding'\n",
            "...processing symbol 'EditDistance'\n",
            "...processing symbol 'BartSeq2SeqLM'\n",
            "...processing symbol 'AlbertTokenizer'\n",
            "...processing symbol 'RobertaPreprocessor'\n",
            "...processing symbol 'RobertaMaskedLM'\n",
            "...processing symbol 'RotaryEmbedding'\n",
            "...processing symbol 'AlbertMaskedLM'\n",
            "...processing symbol 'PositionEmbedding'\n",
            "...processing symbol 'GPTNeoXCausalLMPreprocessor'\n",
            "...processing symbol 'BloomBackbone'\n",
            "...processing symbol 'XLMRobertaClassifier'\n",
            "...processing symbol 'RobertaBackbone'\n",
            "...processing symbol 'ElectraBackbone'\n",
            "...processing symbol 'LlamaTokenizer'\n",
            "...processing symbol 'DistilBertMaskedLM'\n",
            "...processing symbol 'RobertaClassifier'\n",
            "...processing symbol 'MistralPreprocessor'\n",
            "...processing symbol 'MaskedLMMaskGenerator'\n",
            "...processing symbol 'Bleu'\n",
            "...processing symbol 'BertBackbone'\n",
            "...processing symbol 'Perplexity'\n",
            "...processing symbol 'BartPreprocessor'\n",
            "...processing symbol 'OPTBackbone'\n",
            "...processing symbol 'OPTTokenizer'\n",
            "...processing symbol 'GPT2CausalLM'\n",
            "...processing symbol 'MaskedLMHead'\n",
            "...processing symbol 'BeamSampler'\n",
            "...processing symbol 'XLMRobertaMaskedLMPreprocessor'\n",
            "...processing symbol 'CachedMultiHeadAttention'\n",
            "...processing symbol 'GPTNeoXTokenizer'\n",
            "...processing symbol 'MultiSegmentPacker'\n",
            "...processing symbol 'Tokenizer'\n",
            "...processing symbol 'XLNetBackbone'\n",
            "...processing symbol 'FNetTokenizer'\n",
            "...processing symbol 'AlbertBackbone'\n",
            "...processing symbol 'UnicodeCodepointTokenizer'\n",
            "...processing symbol 'ElectraTokenizer'\n",
            "...processing symbol 'RougeN'\n",
            "...processing symbol 'GPT2Tokenizer'\n",
            "...processing symbol 'RobertaTokenizer'\n",
            "...processing symbol 'BertMaskedLMPreprocessor'\n",
            "...processing symbol 'GMiniBackbone'\n",
            "...processing symbol 'ContrastiveSampler'\n",
            "...processing symbol 'GPT2CausalLMPreprocessor'\n",
            "...processing symbol 'GPTNeoXCausalLM'\n",
            "...processing symbol 'WhisperBackbone'\n",
            "...processing symbol 'RandomDeletion'\n",
            "...processing symbol 'compute_sentence_piece_proto'\n",
            "...processing symbol 'GPT2Backbone'\n",
            "...processing symbol 'T5Tokenizer'\n",
            "...processing symbol 'BertTokenizer'\n",
            "...processing symbol 'TransformerEncoder'\n",
            "...processing symbol 'OPTCausalLM'\n",
            "...processing symbol 'TopKSampler'\n",
            "Writing out API files.\n",
            "...writing keras_nlp/models/__init__.py\n",
            "...writing keras_nlp/__init__.py\n",
            "...writing keras_nlp/tokenizers/__init__.py\n",
            "...writing keras_nlp/layers/__init__.py\n",
            "...writing keras_nlp/samplers/__init__.py\n",
            "...writing keras_nlp/metrics/__init__.py\n",
            "\u001b[1m* Creating venv isolated environment...\u001b[0m\n",
            "\u001b[1m* Installing packages in isolated environment... (setuptools >= 40.8.0, wheel)\u001b[0m\n",
            "\u001b[1m* Getting build dependencies for sdist...\u001b[0m\n",
            "running egg_info\n",
            "creating keras_nlp.egg-info\n",
            "writing keras_nlp.egg-info/PKG-INFO\n",
            "writing dependency_links to keras_nlp.egg-info/dependency_links.txt\n",
            "writing requirements to keras_nlp.egg-info/requires.txt\n",
            "writing top-level names to keras_nlp.egg-info/top_level.txt\n",
            "writing manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "reading manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "writing manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "\u001b[1m* Building sdist...\u001b[0m\n",
            "running sdist\n",
            "running egg_info\n",
            "writing keras_nlp.egg-info/PKG-INFO\n",
            "writing dependency_links to keras_nlp.egg-info/dependency_links.txt\n",
            "writing requirements to keras_nlp.egg-info/requires.txt\n",
            "writing top-level names to keras_nlp.egg-info/top_level.txt\n",
            "reading manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "writing manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "running check\n",
            "creating keras-nlp-0.7.0\n",
            "creating keras-nlp-0.7.0/keras_nlp\n",
            "creating keras-nlp-0.7.0/keras_nlp.egg-info\n",
            "creating keras-nlp-0.7.0/keras_nlp/layers\n",
            "creating keras-nlp-0.7.0/keras_nlp/metrics\n",
            "creating keras-nlp-0.7.0/keras_nlp/models\n",
            "creating keras-nlp-0.7.0/keras_nlp/samplers\n",
            "creating keras-nlp-0.7.0/keras_nlp/src\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/backend\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/layers\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/layers/preprocessing\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/metrics\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/bart\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/bloom\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/electra\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/gpt2\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/llama\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/mistral\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/opt\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/t5\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/models/xlnet\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/tests\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "creating keras-nlp-0.7.0/keras_nlp/src/utils\n",
            "creating keras-nlp-0.7.0/keras_nlp/tokenizers\n",
            "copying files to keras-nlp-0.7.0...\n",
            "copying README.md -> keras-nlp-0.7.0\n",
            "copying setup.cfg -> keras-nlp-0.7.0\n",
            "copying setup.py -> keras-nlp-0.7.0\n",
            "copying keras_nlp/__init__.py -> keras-nlp-0.7.0/keras_nlp\n",
            "copying keras_nlp.egg-info/PKG-INFO -> keras-nlp-0.7.0/keras_nlp.egg-info\n",
            "copying keras_nlp.egg-info/SOURCES.txt -> keras-nlp-0.7.0/keras_nlp.egg-info\n",
            "copying keras_nlp.egg-info/dependency_links.txt -> keras-nlp-0.7.0/keras_nlp.egg-info\n",
            "copying keras_nlp.egg-info/requires.txt -> keras-nlp-0.7.0/keras_nlp.egg-info\n",
            "copying keras_nlp.egg-info/top_level.txt -> keras-nlp-0.7.0/keras_nlp.egg-info\n",
            "copying keras_nlp/layers/__init__.py -> keras-nlp-0.7.0/keras_nlp/layers\n",
            "copying keras_nlp/metrics/__init__.py -> keras-nlp-0.7.0/keras_nlp/metrics\n",
            "copying keras_nlp/models/__init__.py -> keras-nlp-0.7.0/keras_nlp/models\n",
            "copying keras_nlp/samplers/__init__.py -> keras-nlp-0.7.0/keras_nlp/samplers\n",
            "copying keras_nlp/src/__init__.py -> keras-nlp-0.7.0/keras_nlp/src\n",
            "copying keras_nlp/src/api_export.py -> keras-nlp-0.7.0/keras_nlp/src\n",
            "copying keras_nlp/src/conftest.py -> keras-nlp-0.7.0/keras_nlp/src\n",
            "copying keras_nlp/src/version_utils.py -> keras-nlp-0.7.0/keras_nlp/src\n",
            "copying keras_nlp/src/backend/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/config.py -> keras-nlp-0.7.0/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/keras.py -> keras-nlp-0.7.0/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/ops.py -> keras-nlp-0.7.0/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/random.py -> keras-nlp-0.7.0/keras_nlp/src/backend\n",
            "copying keras_nlp/src/layers/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/layers\n",
            "copying keras_nlp/src/layers/modeling/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/cached_multi_head_attention.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/f_net_encoder.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/masked_lm_head.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/position_embedding.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/reversible_embedding.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/rotary_embedding.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/sine_position_encoding.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/token_and_position_embedding.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/transformer_decoder.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/transformer_encoder.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/transformer_layer_utils.py -> keras-nlp-0.7.0/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/preprocessing/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/masked_lm_mask_generator.py -> keras-nlp-0.7.0/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/multi_segment_packer.py -> keras-nlp-0.7.0/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/preprocessing_layer.py -> keras-nlp-0.7.0/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/random_deletion.py -> keras-nlp-0.7.0/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/random_swap.py -> keras-nlp-0.7.0/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/start_end_packer.py -> keras-nlp-0.7.0/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/metrics/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/bleu.py -> keras-nlp-0.7.0/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/edit_distance.py -> keras-nlp-0.7.0/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/perplexity.py -> keras-nlp-0.7.0/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/rouge_base.py -> keras-nlp-0.7.0/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/rouge_l.py -> keras-nlp-0.7.0/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/rouge_n.py -> keras-nlp-0.7.0/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/models/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/generative_task.py -> keras-nlp-0.7.0/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/task.py -> keras-nlp-0.7.0/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/albert/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_classifier.py -> keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_masked_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_masked_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/bart/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_seq_2_seq_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_seq_2_seq_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bert/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_classifier.py -> keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_masked_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_masked_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bloom/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/bloom\n",
            "copying keras_nlp/src/models/bloom/bloom_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/bloom\n",
            "copying keras_nlp/src/models/bloom/bloom_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/bloom\n",
            "copying keras_nlp/src/models/bloom/bloom_decoder.py -> keras-nlp-0.7.0/keras_nlp/src/models/bloom\n",
            "copying keras_nlp/src/models/deberta_v3/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_classifier.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/disentangled_attention_encoder.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/disentangled_self_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/relative_embedding.py -> keras-nlp-0.7.0/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/distil_bert/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_classifier.py -> keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_masked_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_masked_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/electra/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/electra\n",
            "copying keras_nlp/src/models/electra/electra_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/electra\n",
            "copying keras_nlp/src/models/electra/electra_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/electra\n",
            "copying keras_nlp/src/models/f_net/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_classifier.py -> keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_masked_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_masked_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/g_mini/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_causal_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_causal_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_decoder_block.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/rms_normalization.py -> keras-nlp-0.7.0/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/gpt2/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_causal_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_causal_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt_neo_x/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_decoder.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/llama/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_decoder.py -> keras-nlp-0.7.0/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_layernorm.py -> keras-nlp-0.7.0/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/mistral/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_layer_norm.py -> keras-nlp-0.7.0/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_transformer_decoder.py -> keras-nlp-0.7.0/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/opt/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_causal_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_causal_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/roberta/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_classifier.py -> keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_masked_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_masked_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/t5/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_layer_norm.py -> keras-nlp-0.7.0/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_multi_head_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_transformer_layer.py -> keras-nlp-0.7.0/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/whisper/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_audio_feature_extractor.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_cached_multi_head_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_decoder.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_encoder.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/xlm_roberta/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_classifier.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_preprocessor.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_presets.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlnet/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/relative_attention.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/xlnet_backbone.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/xlnet_content_and_query_embedding.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/xlnet_encoder.py -> keras-nlp-0.7.0/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/samplers/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/beam_sampler.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/contrastive_sampler.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/greedy_sampler.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/random_sampler.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/sampler.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/serialization.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/top_k_sampler.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/top_p_sampler.py -> keras-nlp-0.7.0/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/tests/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/tests\n",
            "copying keras_nlp/src/tests/test_case.py -> keras-nlp-0.7.0/keras_nlp/src/tests\n",
            "copying keras_nlp/src/tokenizers/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/byte_pair_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/byte_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/sentence_piece_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/sentence_piece_tokenizer_trainer.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/unicode_codepoint_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/word_piece_tokenizer.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/word_piece_tokenizer_trainer.py -> keras-nlp-0.7.0/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/utils/__init__.py -> keras-nlp-0.7.0/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/keras_utils.py -> keras-nlp-0.7.0/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/pipeline_model.py -> keras-nlp-0.7.0/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/preset_utils.py -> keras-nlp-0.7.0/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/python_utils.py -> keras-nlp-0.7.0/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/tensor_utils.py -> keras-nlp-0.7.0/keras_nlp/src/utils\n",
            "copying keras_nlp/tokenizers/__init__.py -> keras-nlp-0.7.0/keras_nlp/tokenizers\n",
            "copying keras_nlp.egg-info/SOURCES.txt -> keras-nlp-0.7.0/keras_nlp.egg-info\n",
            "Writing keras-nlp-0.7.0/setup.cfg\n",
            "Creating tar archive\n",
            "removing 'keras-nlp-0.7.0' (and everything under it)\n",
            "\u001b[1m* Building wheel from sdist\u001b[0m\n",
            "\u001b[1m* Creating venv isolated environment...\u001b[0m\n",
            "\u001b[1m* Installing packages in isolated environment... (setuptools >= 40.8.0, wheel)\u001b[0m\n",
            "\u001b[1m* Getting build dependencies for wheel...\u001b[0m\n",
            "running egg_info\n",
            "writing keras_nlp.egg-info/PKG-INFO\n",
            "writing dependency_links to keras_nlp.egg-info/dependency_links.txt\n",
            "writing requirements to keras_nlp.egg-info/requires.txt\n",
            "writing top-level names to keras_nlp.egg-info/top_level.txt\n",
            "reading manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "writing manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "\u001b[1m* Installing packages in isolated environment... (wheel)\u001b[0m\n",
            "\u001b[1m* Building wheel...\u001b[0m\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/keras_nlp\n",
            "copying keras_nlp/__init__.py -> build/lib/keras_nlp\n",
            "creating build/lib/keras_nlp/src\n",
            "copying keras_nlp/src/conftest.py -> build/lib/keras_nlp/src\n",
            "copying keras_nlp/src/api_export.py -> build/lib/keras_nlp/src\n",
            "copying keras_nlp/src/__init__.py -> build/lib/keras_nlp/src\n",
            "copying keras_nlp/src/version_utils.py -> build/lib/keras_nlp/src\n",
            "creating build/lib/keras_nlp/layers\n",
            "copying keras_nlp/layers/__init__.py -> build/lib/keras_nlp/layers\n",
            "creating build/lib/keras_nlp/metrics\n",
            "copying keras_nlp/metrics/__init__.py -> build/lib/keras_nlp/metrics\n",
            "creating build/lib/keras_nlp/samplers\n",
            "copying keras_nlp/samplers/__init__.py -> build/lib/keras_nlp/samplers\n",
            "creating build/lib/keras_nlp/tokenizers\n",
            "copying keras_nlp/tokenizers/__init__.py -> build/lib/keras_nlp/tokenizers\n",
            "creating build/lib/keras_nlp/models\n",
            "copying keras_nlp/models/__init__.py -> build/lib/keras_nlp/models\n",
            "creating build/lib/keras_nlp/src/tests\n",
            "copying keras_nlp/src/tests/test_case.py -> build/lib/keras_nlp/src/tests\n",
            "copying keras_nlp/src/tests/__init__.py -> build/lib/keras_nlp/src/tests\n",
            "creating build/lib/keras_nlp/src/layers\n",
            "copying keras_nlp/src/layers/__init__.py -> build/lib/keras_nlp/src/layers\n",
            "creating build/lib/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/edit_distance.py -> build/lib/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/rouge_n.py -> build/lib/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/rouge_base.py -> build/lib/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/__init__.py -> build/lib/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/bleu.py -> build/lib/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/rouge_l.py -> build/lib/keras_nlp/src/metrics\n",
            "copying keras_nlp/src/metrics/perplexity.py -> build/lib/keras_nlp/src/metrics\n",
            "creating build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/__init__.py -> build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/random_sampler.py -> build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/serialization.py -> build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/greedy_sampler.py -> build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/sampler.py -> build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/top_p_sampler.py -> build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/beam_sampler.py -> build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/contrastive_sampler.py -> build/lib/keras_nlp/src/samplers\n",
            "copying keras_nlp/src/samplers/top_k_sampler.py -> build/lib/keras_nlp/src/samplers\n",
            "creating build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/word_piece_tokenizer_trainer.py -> build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/byte_pair_tokenizer.py -> build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/__init__.py -> build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/tokenizer.py -> build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/byte_tokenizer.py -> build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/word_piece_tokenizer.py -> build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/sentence_piece_tokenizer.py -> build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/unicode_codepoint_tokenizer.py -> build/lib/keras_nlp/src/tokenizers\n",
            "copying keras_nlp/src/tokenizers/sentence_piece_tokenizer_trainer.py -> build/lib/keras_nlp/src/tokenizers\n",
            "creating build/lib/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/__init__.py -> build/lib/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/keras_utils.py -> build/lib/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/pipeline_model.py -> build/lib/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/tensor_utils.py -> build/lib/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/python_utils.py -> build/lib/keras_nlp/src/utils\n",
            "copying keras_nlp/src/utils/preset_utils.py -> build/lib/keras_nlp/src/utils\n",
            "creating build/lib/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/random.py -> build/lib/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/__init__.py -> build/lib/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/keras.py -> build/lib/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/ops.py -> build/lib/keras_nlp/src/backend\n",
            "copying keras_nlp/src/backend/config.py -> build/lib/keras_nlp/src/backend\n",
            "creating build/lib/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/preprocessor.py -> build/lib/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/__init__.py -> build/lib/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/task.py -> build/lib/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/generative_task.py -> build/lib/keras_nlp/src/models\n",
            "copying keras_nlp/src/models/backbone.py -> build/lib/keras_nlp/src/models\n",
            "creating build/lib/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/start_end_packer.py -> build/lib/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/__init__.py -> build/lib/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/multi_segment_packer.py -> build/lib/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/masked_lm_mask_generator.py -> build/lib/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/preprocessing_layer.py -> build/lib/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/random_deletion.py -> build/lib/keras_nlp/src/layers/preprocessing\n",
            "copying keras_nlp/src/layers/preprocessing/random_swap.py -> build/lib/keras_nlp/src/layers/preprocessing\n",
            "creating build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/transformer_layer_utils.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/masked_lm_head.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/transformer_decoder.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/__init__.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/transformer_encoder.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/sine_position_encoding.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/position_embedding.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/cached_multi_head_attention.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/rotary_embedding.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/f_net_encoder.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/reversible_embedding.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "copying keras_nlp/src/layers/modeling/token_and_position_embedding.py -> build/lib/keras_nlp/src/layers/modeling\n",
            "creating build/lib/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_attention.py -> build/lib/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/__init__.py -> build/lib/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_backbone.py -> build/lib/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_tokenizer.py -> build/lib/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_layernorm.py -> build/lib/keras_nlp/src/models/llama\n",
            "copying keras_nlp/src/models/llama/llama_decoder.py -> build/lib/keras_nlp/src/models/llama\n",
            "creating build/lib/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_presets.py -> build/lib/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/__init__.py -> build/lib/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_backbone.py -> build/lib/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_preprocessor.py -> build/lib/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_causal_lm_preprocessor.py -> build/lib/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_causal_lm.py -> build/lib/keras_nlp/src/models/gpt2\n",
            "copying keras_nlp/src/models/gpt2/gpt2_tokenizer.py -> build/lib/keras_nlp/src/models/gpt2\n",
            "creating build/lib/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_preprocessor.py -> build/lib/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/__init__.py -> build/lib/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_classifier.py -> build/lib/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_presets.py -> build/lib/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm_preprocessor.py -> build/lib/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_tokenizer.py -> build/lib/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm.py -> build/lib/keras_nlp/src/models/xlm_roberta\n",
            "copying keras_nlp/src/models/xlm_roberta/xlm_roberta_backbone.py -> build/lib/keras_nlp/src/models/xlm_roberta\n",
            "creating build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_decoder.py -> build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/__init__.py -> build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm_preprocessor.py -> build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_attention.py -> build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_preprocessor.py -> build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_backbone.py -> build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm.py -> build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "copying keras_nlp/src/models/gpt_neo_x/gpt_neo_x_tokenizer.py -> build/lib/keras_nlp/src/models/gpt_neo_x\n",
            "creating build/lib/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/__init__.py -> build/lib/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/relative_attention.py -> build/lib/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/xlnet_backbone.py -> build/lib/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/xlnet_content_and_query_embedding.py -> build/lib/keras_nlp/src/models/xlnet\n",
            "copying keras_nlp/src/models/xlnet/xlnet_encoder.py -> build/lib/keras_nlp/src/models/xlnet\n",
            "creating build/lib/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_tokenizer.py -> build/lib/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_presets.py -> build/lib/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_preprocessor.py -> build/lib/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/__init__.py -> build/lib/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_backbone.py -> build/lib/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_seq_2_seq_lm_preprocessor.py -> build/lib/keras_nlp/src/models/bart\n",
            "copying keras_nlp/src/models/bart/bart_seq_2_seq_lm.py -> build/lib/keras_nlp/src/models/bart\n",
            "creating build/lib/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/__init__.py -> build/lib/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_classifier.py -> build/lib/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_masked_lm_preprocessor.py -> build/lib/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_preprocessor.py -> build/lib/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_presets.py -> build/lib/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_backbone.py -> build/lib/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_masked_lm.py -> build/lib/keras_nlp/src/models/bert\n",
            "copying keras_nlp/src/models/bert/bert_tokenizer.py -> build/lib/keras_nlp/src/models/bert\n",
            "creating build/lib/keras_nlp/src/models/bloom\n",
            "copying keras_nlp/src/models/bloom/bloom_attention.py -> build/lib/keras_nlp/src/models/bloom\n",
            "copying keras_nlp/src/models/bloom/__init__.py -> build/lib/keras_nlp/src/models/bloom\n",
            "copying keras_nlp/src/models/bloom/bloom_decoder.py -> build/lib/keras_nlp/src/models/bloom\n",
            "copying keras_nlp/src/models/bloom/bloom_backbone.py -> build/lib/keras_nlp/src/models/bloom\n",
            "creating build/lib/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_causal_lm_preprocessor.py -> build/lib/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_preprocessor.py -> build/lib/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_backbone.py -> build/lib/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_tokenizer.py -> build/lib/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_presets.py -> build/lib/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/__init__.py -> build/lib/keras_nlp/src/models/opt\n",
            "copying keras_nlp/src/models/opt/opt_causal_lm.py -> build/lib/keras_nlp/src/models/opt\n",
            "creating build/lib/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_masked_lm_preprocessor.py -> build/lib/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_backbone.py -> build/lib/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/__init__.py -> build/lib/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_masked_lm.py -> build/lib/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_classifier.py -> build/lib/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_preprocessor.py -> build/lib/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_presets.py -> build/lib/keras_nlp/src/models/distil_bert\n",
            "copying keras_nlp/src/models/distil_bert/distil_bert_tokenizer.py -> build/lib/keras_nlp/src/models/distil_bert\n",
            "creating build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_tokenizer.py -> build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_cached_multi_head_attention.py -> build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_preprocessor.py -> build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_encoder.py -> build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/__init__.py -> build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_backbone.py -> build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_audio_feature_extractor.py -> build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_presets.py -> build/lib/keras_nlp/src/models/whisper\n",
            "copying keras_nlp/src/models/whisper/whisper_decoder.py -> build/lib/keras_nlp/src/models/whisper\n",
            "creating build/lib/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_masked_lm_preprocessor.py -> build/lib/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_backbone.py -> build/lib/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/__init__.py -> build/lib/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_tokenizer.py -> build/lib/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_masked_lm.py -> build/lib/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_classifier.py -> build/lib/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_preprocessor.py -> build/lib/keras_nlp/src/models/albert\n",
            "copying keras_nlp/src/models/albert/albert_presets.py -> build/lib/keras_nlp/src/models/albert\n",
            "creating build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_causal_lm_preprocessor.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_preprocessor.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_tokenizer.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_backbone.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_decoder_block.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/__init__.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_presets.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_attention.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/rms_normalization.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "copying keras_nlp/src/models/g_mini/g_mini_causal_lm.py -> build/lib/keras_nlp/src/models/g_mini\n",
            "creating build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/disentangled_attention_encoder.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/__init__.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm_preprocessor.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_classifier.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/disentangled_self_attention.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_presets.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_preprocessor.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_backbone.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/relative_embedding.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "copying keras_nlp/src/models/deberta_v3/deberta_v3_tokenizer.py -> build/lib/keras_nlp/src/models/deberta_v3\n",
            "creating build/lib/keras_nlp/src/models/electra\n",
            "copying keras_nlp/src/models/electra/__init__.py -> build/lib/keras_nlp/src/models/electra\n",
            "copying keras_nlp/src/models/electra/electra_tokenizer.py -> build/lib/keras_nlp/src/models/electra\n",
            "copying keras_nlp/src/models/electra/electra_backbone.py -> build/lib/keras_nlp/src/models/electra\n",
            "creating build/lib/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_backbone.py -> build/lib/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_transformer_decoder.py -> build/lib/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_preprocessor.py -> build/lib/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_tokenizer.py -> build/lib/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/__init__.py -> build/lib/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_layer_norm.py -> build/lib/keras_nlp/src/models/mistral\n",
            "copying keras_nlp/src/models/mistral/mistral_attention.py -> build/lib/keras_nlp/src/models/mistral\n",
            "creating build/lib/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_masked_lm_preprocessor.py -> build/lib/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_classifier.py -> build/lib/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/__init__.py -> build/lib/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_masked_lm.py -> build/lib/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_preprocessor.py -> build/lib/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_backbone.py -> build/lib/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_presets.py -> build/lib/keras_nlp/src/models/f_net\n",
            "copying keras_nlp/src/models/f_net/f_net_tokenizer.py -> build/lib/keras_nlp/src/models/f_net\n",
            "creating build/lib/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_masked_lm_preprocessor.py -> build/lib/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/__init__.py -> build/lib/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_tokenizer.py -> build/lib/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_masked_lm.py -> build/lib/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_backbone.py -> build/lib/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_presets.py -> build/lib/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_classifier.py -> build/lib/keras_nlp/src/models/roberta\n",
            "copying keras_nlp/src/models/roberta/roberta_preprocessor.py -> build/lib/keras_nlp/src/models/roberta\n",
            "creating build/lib/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_presets.py -> build/lib/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_layer_norm.py -> build/lib/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/__init__.py -> build/lib/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_backbone.py -> build/lib/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_tokenizer.py -> build/lib/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_multi_head_attention.py -> build/lib/keras_nlp/src/models/t5\n",
            "copying keras_nlp/src/models/t5/t5_transformer_layer.py -> build/lib/keras_nlp/src/models/t5\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src\n",
            "copying build/lib/keras_nlp/src/conftest.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src\n",
            "copying build/lib/keras_nlp/src/api_export.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/tests\n",
            "copying build/lib/keras_nlp/src/tests/test_case.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tests\n",
            "copying build/lib/keras_nlp/src/tests/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tests\n",
            "copying build/lib/keras_nlp/src/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/layers\n",
            "copying build/lib/keras_nlp/src/layers/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/preprocessing\n",
            "copying build/lib/keras_nlp/src/layers/preprocessing/start_end_packer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/preprocessing\n",
            "copying build/lib/keras_nlp/src/layers/preprocessing/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/preprocessing\n",
            "copying build/lib/keras_nlp/src/layers/preprocessing/multi_segment_packer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/preprocessing\n",
            "copying build/lib/keras_nlp/src/layers/preprocessing/masked_lm_mask_generator.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/preprocessing\n",
            "copying build/lib/keras_nlp/src/layers/preprocessing/preprocessing_layer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/preprocessing\n",
            "copying build/lib/keras_nlp/src/layers/preprocessing/random_deletion.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/preprocessing\n",
            "copying build/lib/keras_nlp/src/layers/preprocessing/random_swap.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/preprocessing\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/transformer_layer_utils.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/masked_lm_head.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/transformer_decoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/transformer_encoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/sine_position_encoding.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/position_embedding.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/cached_multi_head_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/rotary_embedding.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/f_net_encoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/reversible_embedding.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "copying build/lib/keras_nlp/src/layers/modeling/token_and_position_embedding.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/layers/modeling\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/metrics\n",
            "copying build/lib/keras_nlp/src/metrics/edit_distance.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/metrics\n",
            "copying build/lib/keras_nlp/src/metrics/rouge_n.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/metrics\n",
            "copying build/lib/keras_nlp/src/metrics/rouge_base.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/metrics\n",
            "copying build/lib/keras_nlp/src/metrics/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/metrics\n",
            "copying build/lib/keras_nlp/src/metrics/bleu.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/metrics\n",
            "copying build/lib/keras_nlp/src/metrics/rouge_l.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/metrics\n",
            "copying build/lib/keras_nlp/src/metrics/perplexity.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/metrics\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/random_sampler.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/serialization.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/greedy_sampler.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/sampler.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/top_p_sampler.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/beam_sampler.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/contrastive_sampler.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "copying build/lib/keras_nlp/src/samplers/top_k_sampler.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/samplers\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/word_piece_tokenizer_trainer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/byte_pair_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/byte_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/word_piece_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/sentence_piece_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/unicode_codepoint_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "copying build/lib/keras_nlp/src/tokenizers/sentence_piece_tokenizer_trainer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/tokenizers\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/utils\n",
            "copying build/lib/keras_nlp/src/utils/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/utils\n",
            "copying build/lib/keras_nlp/src/utils/keras_utils.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/utils\n",
            "copying build/lib/keras_nlp/src/utils/pipeline_model.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/utils\n",
            "copying build/lib/keras_nlp/src/utils/tensor_utils.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/utils\n",
            "copying build/lib/keras_nlp/src/utils/python_utils.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/utils\n",
            "copying build/lib/keras_nlp/src/utils/preset_utils.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/utils\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/backend\n",
            "copying build/lib/keras_nlp/src/backend/random.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/backend\n",
            "copying build/lib/keras_nlp/src/backend/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/backend\n",
            "copying build/lib/keras_nlp/src/backend/keras.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/backend\n",
            "copying build/lib/keras_nlp/src/backend/ops.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/backend\n",
            "copying build/lib/keras_nlp/src/backend/config.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/backend\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/llama\n",
            "copying build/lib/keras_nlp/src/models/llama/llama_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/llama\n",
            "copying build/lib/keras_nlp/src/models/llama/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/llama\n",
            "copying build/lib/keras_nlp/src/models/llama/llama_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/llama\n",
            "copying build/lib/keras_nlp/src/models/llama/llama_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/llama\n",
            "copying build/lib/keras_nlp/src/models/llama/llama_layernorm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/llama\n",
            "copying build/lib/keras_nlp/src/models/llama/llama_decoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/llama\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt2\n",
            "copying build/lib/keras_nlp/src/models/gpt2/gpt2_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt2\n",
            "copying build/lib/keras_nlp/src/models/gpt2/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt2\n",
            "copying build/lib/keras_nlp/src/models/gpt2/gpt2_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt2\n",
            "copying build/lib/keras_nlp/src/models/gpt2/gpt2_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt2\n",
            "copying build/lib/keras_nlp/src/models/gpt2/gpt2_causal_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt2\n",
            "copying build/lib/keras_nlp/src/models/gpt2/gpt2_causal_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt2\n",
            "copying build/lib/keras_nlp/src/models/gpt2/gpt2_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt2\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "copying build/lib/keras_nlp/src/models/xlm_roberta/xlm_roberta_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "copying build/lib/keras_nlp/src/models/xlm_roberta/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "copying build/lib/keras_nlp/src/models/xlm_roberta/xlm_roberta_classifier.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "copying build/lib/keras_nlp/src/models/xlm_roberta/xlm_roberta_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "copying build/lib/keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "copying build/lib/keras_nlp/src/models/xlm_roberta/xlm_roberta_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "copying build/lib/keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "copying build/lib/keras_nlp/src/models/xlm_roberta/xlm_roberta_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlm_roberta\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "copying build/lib/keras_nlp/src/models/gpt_neo_x/gpt_neo_x_decoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "copying build/lib/keras_nlp/src/models/gpt_neo_x/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "copying build/lib/keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "copying build/lib/keras_nlp/src/models/gpt_neo_x/gpt_neo_x_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "copying build/lib/keras_nlp/src/models/gpt_neo_x/gpt_neo_x_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "copying build/lib/keras_nlp/src/models/gpt_neo_x/gpt_neo_x_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "copying build/lib/keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "copying build/lib/keras_nlp/src/models/gpt_neo_x/gpt_neo_x_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/gpt_neo_x\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlnet\n",
            "copying build/lib/keras_nlp/src/models/xlnet/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlnet\n",
            "copying build/lib/keras_nlp/src/models/xlnet/relative_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlnet\n",
            "copying build/lib/keras_nlp/src/models/xlnet/xlnet_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlnet\n",
            "copying build/lib/keras_nlp/src/models/xlnet/xlnet_content_and_query_embedding.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlnet\n",
            "copying build/lib/keras_nlp/src/models/xlnet/xlnet_encoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/xlnet\n",
            "copying build/lib/keras_nlp/src/models/preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bart\n",
            "copying build/lib/keras_nlp/src/models/bart/bart_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bart\n",
            "copying build/lib/keras_nlp/src/models/bart/bart_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bart\n",
            "copying build/lib/keras_nlp/src/models/bart/bart_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bart\n",
            "copying build/lib/keras_nlp/src/models/bart/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bart\n",
            "copying build/lib/keras_nlp/src/models/bart/bart_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bart\n",
            "copying build/lib/keras_nlp/src/models/bart/bart_seq_2_seq_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bart\n",
            "copying build/lib/keras_nlp/src/models/bart/bart_seq_2_seq_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bart\n",
            "copying build/lib/keras_nlp/src/models/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "copying build/lib/keras_nlp/src/models/bert/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "copying build/lib/keras_nlp/src/models/bert/bert_classifier.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "copying build/lib/keras_nlp/src/models/bert/bert_masked_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "copying build/lib/keras_nlp/src/models/bert/bert_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "copying build/lib/keras_nlp/src/models/bert/bert_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "copying build/lib/keras_nlp/src/models/bert/bert_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "copying build/lib/keras_nlp/src/models/bert/bert_masked_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "copying build/lib/keras_nlp/src/models/bert/bert_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bert\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bloom\n",
            "copying build/lib/keras_nlp/src/models/bloom/bloom_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bloom\n",
            "copying build/lib/keras_nlp/src/models/bloom/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bloom\n",
            "copying build/lib/keras_nlp/src/models/bloom/bloom_decoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bloom\n",
            "copying build/lib/keras_nlp/src/models/bloom/bloom_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/bloom\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/opt\n",
            "copying build/lib/keras_nlp/src/models/opt/opt_causal_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/opt\n",
            "copying build/lib/keras_nlp/src/models/opt/opt_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/opt\n",
            "copying build/lib/keras_nlp/src/models/opt/opt_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/opt\n",
            "copying build/lib/keras_nlp/src/models/opt/opt_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/opt\n",
            "copying build/lib/keras_nlp/src/models/opt/opt_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/opt\n",
            "copying build/lib/keras_nlp/src/models/opt/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/opt\n",
            "copying build/lib/keras_nlp/src/models/opt/opt_causal_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/opt\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "copying build/lib/keras_nlp/src/models/distil_bert/distil_bert_masked_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "copying build/lib/keras_nlp/src/models/distil_bert/distil_bert_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "copying build/lib/keras_nlp/src/models/distil_bert/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "copying build/lib/keras_nlp/src/models/distil_bert/distil_bert_masked_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "copying build/lib/keras_nlp/src/models/distil_bert/distil_bert_classifier.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "copying build/lib/keras_nlp/src/models/distil_bert/distil_bert_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "copying build/lib/keras_nlp/src/models/distil_bert/distil_bert_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "copying build/lib/keras_nlp/src/models/distil_bert/distil_bert_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/distil_bert\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/whisper_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/whisper_cached_multi_head_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/whisper_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/whisper_encoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/whisper_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/whisper_audio_feature_extractor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/whisper_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "copying build/lib/keras_nlp/src/models/whisper/whisper_decoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/whisper\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/albert/albert_masked_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/albert/albert_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/albert/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/albert/albert_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/albert/albert_masked_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/albert/albert_classifier.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/albert/albert_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/albert/albert_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/albert\n",
            "copying build/lib/keras_nlp/src/models/task.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/g_mini_causal_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/g_mini_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/g_mini_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/g_mini_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/g_mini_decoder_block.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/g_mini_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/g_mini_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/rms_normalization.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "copying build/lib/keras_nlp/src/models/g_mini/g_mini_causal_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/g_mini\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/disentangled_attention_encoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/deberta_v3_classifier.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/disentangled_self_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/deberta_v3_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/deberta_v3_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/deberta_v3_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/relative_embedding.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "copying build/lib/keras_nlp/src/models/deberta_v3/deberta_v3_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/deberta_v3\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/electra\n",
            "copying build/lib/keras_nlp/src/models/electra/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/electra\n",
            "copying build/lib/keras_nlp/src/models/electra/electra_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/electra\n",
            "copying build/lib/keras_nlp/src/models/electra/electra_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/electra\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/mistral\n",
            "copying build/lib/keras_nlp/src/models/mistral/mistral_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/mistral\n",
            "copying build/lib/keras_nlp/src/models/mistral/mistral_transformer_decoder.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/mistral\n",
            "copying build/lib/keras_nlp/src/models/mistral/mistral_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/mistral\n",
            "copying build/lib/keras_nlp/src/models/mistral/mistral_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/mistral\n",
            "copying build/lib/keras_nlp/src/models/mistral/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/mistral\n",
            "copying build/lib/keras_nlp/src/models/mistral/mistral_layer_norm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/mistral\n",
            "copying build/lib/keras_nlp/src/models/mistral/mistral_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/mistral\n",
            "copying build/lib/keras_nlp/src/models/generative_task.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "copying build/lib/keras_nlp/src/models/f_net/f_net_masked_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "copying build/lib/keras_nlp/src/models/f_net/f_net_classifier.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "copying build/lib/keras_nlp/src/models/f_net/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "copying build/lib/keras_nlp/src/models/f_net/f_net_masked_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "copying build/lib/keras_nlp/src/models/f_net/f_net_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "copying build/lib/keras_nlp/src/models/f_net/f_net_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "copying build/lib/keras_nlp/src/models/f_net/f_net_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "copying build/lib/keras_nlp/src/models/f_net/f_net_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/f_net\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/roberta/roberta_masked_lm_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/roberta/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/roberta/roberta_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/roberta/roberta_masked_lm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/roberta/roberta_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/roberta/roberta_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/roberta/roberta_classifier.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/roberta/roberta_preprocessor.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/roberta\n",
            "copying build/lib/keras_nlp/src/models/backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/src/models/t5\n",
            "copying build/lib/keras_nlp/src/models/t5/t5_presets.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/t5\n",
            "copying build/lib/keras_nlp/src/models/t5/t5_layer_norm.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/t5\n",
            "copying build/lib/keras_nlp/src/models/t5/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/t5\n",
            "copying build/lib/keras_nlp/src/models/t5/t5_backbone.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/t5\n",
            "copying build/lib/keras_nlp/src/models/t5/t5_tokenizer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/t5\n",
            "copying build/lib/keras_nlp/src/models/t5/t5_multi_head_attention.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/t5\n",
            "copying build/lib/keras_nlp/src/models/t5/t5_transformer_layer.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src/models/t5\n",
            "copying build/lib/keras_nlp/src/version_utils.py -> build/bdist.linux-x86_64/wheel/keras_nlp/src\n",
            "copying build/lib/keras_nlp/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/layers\n",
            "copying build/lib/keras_nlp/layers/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/layers\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/metrics\n",
            "copying build/lib/keras_nlp/metrics/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/metrics\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/samplers\n",
            "copying build/lib/keras_nlp/samplers/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/samplers\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/tokenizers\n",
            "copying build/lib/keras_nlp/tokenizers/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/tokenizers\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp/models\n",
            "copying build/lib/keras_nlp/models/__init__.py -> build/bdist.linux-x86_64/wheel/keras_nlp/models\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "writing keras_nlp.egg-info/PKG-INFO\n",
            "writing dependency_links to keras_nlp.egg-info/dependency_links.txt\n",
            "writing requirements to keras_nlp.egg-info/requires.txt\n",
            "writing top-level names to keras_nlp.egg-info/top_level.txt\n",
            "reading manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "writing manifest file 'keras_nlp.egg-info/SOURCES.txt'\n",
            "Copying keras_nlp.egg-info to build/bdist.linux-x86_64/wheel/keras_nlp-0.7.0-py3.10.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/keras_nlp-0.7.0.dist-info/WHEEL\n",
            "creating '/content/keras-nlp-g-mini/tmp_build_dir/dist/.tmp-dld2n9dx/keras_nlp-0.7.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'keras_nlp/__init__.py'\n",
            "adding 'keras_nlp/layers/__init__.py'\n",
            "adding 'keras_nlp/metrics/__init__.py'\n",
            "adding 'keras_nlp/models/__init__.py'\n",
            "adding 'keras_nlp/samplers/__init__.py'\n",
            "adding 'keras_nlp/src/__init__.py'\n",
            "adding 'keras_nlp/src/api_export.py'\n",
            "adding 'keras_nlp/src/conftest.py'\n",
            "adding 'keras_nlp/src/version_utils.py'\n",
            "adding 'keras_nlp/src/backend/__init__.py'\n",
            "adding 'keras_nlp/src/backend/config.py'\n",
            "adding 'keras_nlp/src/backend/keras.py'\n",
            "adding 'keras_nlp/src/backend/ops.py'\n",
            "adding 'keras_nlp/src/backend/random.py'\n",
            "adding 'keras_nlp/src/layers/__init__.py'\n",
            "adding 'keras_nlp/src/layers/modeling/__init__.py'\n",
            "adding 'keras_nlp/src/layers/modeling/cached_multi_head_attention.py'\n",
            "adding 'keras_nlp/src/layers/modeling/f_net_encoder.py'\n",
            "adding 'keras_nlp/src/layers/modeling/masked_lm_head.py'\n",
            "adding 'keras_nlp/src/layers/modeling/position_embedding.py'\n",
            "adding 'keras_nlp/src/layers/modeling/reversible_embedding.py'\n",
            "adding 'keras_nlp/src/layers/modeling/rotary_embedding.py'\n",
            "adding 'keras_nlp/src/layers/modeling/sine_position_encoding.py'\n",
            "adding 'keras_nlp/src/layers/modeling/token_and_position_embedding.py'\n",
            "adding 'keras_nlp/src/layers/modeling/transformer_decoder.py'\n",
            "adding 'keras_nlp/src/layers/modeling/transformer_encoder.py'\n",
            "adding 'keras_nlp/src/layers/modeling/transformer_layer_utils.py'\n",
            "adding 'keras_nlp/src/layers/preprocessing/__init__.py'\n",
            "adding 'keras_nlp/src/layers/preprocessing/masked_lm_mask_generator.py'\n",
            "adding 'keras_nlp/src/layers/preprocessing/multi_segment_packer.py'\n",
            "adding 'keras_nlp/src/layers/preprocessing/preprocessing_layer.py'\n",
            "adding 'keras_nlp/src/layers/preprocessing/random_deletion.py'\n",
            "adding 'keras_nlp/src/layers/preprocessing/random_swap.py'\n",
            "adding 'keras_nlp/src/layers/preprocessing/start_end_packer.py'\n",
            "adding 'keras_nlp/src/metrics/__init__.py'\n",
            "adding 'keras_nlp/src/metrics/bleu.py'\n",
            "adding 'keras_nlp/src/metrics/edit_distance.py'\n",
            "adding 'keras_nlp/src/metrics/perplexity.py'\n",
            "adding 'keras_nlp/src/metrics/rouge_base.py'\n",
            "adding 'keras_nlp/src/metrics/rouge_l.py'\n",
            "adding 'keras_nlp/src/metrics/rouge_n.py'\n",
            "adding 'keras_nlp/src/models/__init__.py'\n",
            "adding 'keras_nlp/src/models/backbone.py'\n",
            "adding 'keras_nlp/src/models/generative_task.py'\n",
            "adding 'keras_nlp/src/models/preprocessor.py'\n",
            "adding 'keras_nlp/src/models/task.py'\n",
            "adding 'keras_nlp/src/models/albert/__init__.py'\n",
            "adding 'keras_nlp/src/models/albert/albert_backbone.py'\n",
            "adding 'keras_nlp/src/models/albert/albert_classifier.py'\n",
            "adding 'keras_nlp/src/models/albert/albert_masked_lm.py'\n",
            "adding 'keras_nlp/src/models/albert/albert_masked_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/albert/albert_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/albert/albert_presets.py'\n",
            "adding 'keras_nlp/src/models/albert/albert_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/bart/__init__.py'\n",
            "adding 'keras_nlp/src/models/bart/bart_backbone.py'\n",
            "adding 'keras_nlp/src/models/bart/bart_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/bart/bart_presets.py'\n",
            "adding 'keras_nlp/src/models/bart/bart_seq_2_seq_lm.py'\n",
            "adding 'keras_nlp/src/models/bart/bart_seq_2_seq_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/bart/bart_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/bert/__init__.py'\n",
            "adding 'keras_nlp/src/models/bert/bert_backbone.py'\n",
            "adding 'keras_nlp/src/models/bert/bert_classifier.py'\n",
            "adding 'keras_nlp/src/models/bert/bert_masked_lm.py'\n",
            "adding 'keras_nlp/src/models/bert/bert_masked_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/bert/bert_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/bert/bert_presets.py'\n",
            "adding 'keras_nlp/src/models/bert/bert_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/bloom/__init__.py'\n",
            "adding 'keras_nlp/src/models/bloom/bloom_attention.py'\n",
            "adding 'keras_nlp/src/models/bloom/bloom_backbone.py'\n",
            "adding 'keras_nlp/src/models/bloom/bloom_decoder.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/__init__.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/deberta_v3_backbone.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/deberta_v3_classifier.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/deberta_v3_masked_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/deberta_v3_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/deberta_v3_presets.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/deberta_v3_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/disentangled_attention_encoder.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/disentangled_self_attention.py'\n",
            "adding 'keras_nlp/src/models/deberta_v3/relative_embedding.py'\n",
            "adding 'keras_nlp/src/models/distil_bert/__init__.py'\n",
            "adding 'keras_nlp/src/models/distil_bert/distil_bert_backbone.py'\n",
            "adding 'keras_nlp/src/models/distil_bert/distil_bert_classifier.py'\n",
            "adding 'keras_nlp/src/models/distil_bert/distil_bert_masked_lm.py'\n",
            "adding 'keras_nlp/src/models/distil_bert/distil_bert_masked_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/distil_bert/distil_bert_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/distil_bert/distil_bert_presets.py'\n",
            "adding 'keras_nlp/src/models/distil_bert/distil_bert_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/electra/__init__.py'\n",
            "adding 'keras_nlp/src/models/electra/electra_backbone.py'\n",
            "adding 'keras_nlp/src/models/electra/electra_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/f_net/__init__.py'\n",
            "adding 'keras_nlp/src/models/f_net/f_net_backbone.py'\n",
            "adding 'keras_nlp/src/models/f_net/f_net_classifier.py'\n",
            "adding 'keras_nlp/src/models/f_net/f_net_masked_lm.py'\n",
            "adding 'keras_nlp/src/models/f_net/f_net_masked_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/f_net/f_net_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/f_net/f_net_presets.py'\n",
            "adding 'keras_nlp/src/models/f_net/f_net_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/g_mini/__init__.py'\n",
            "adding 'keras_nlp/src/models/g_mini/g_mini_attention.py'\n",
            "adding 'keras_nlp/src/models/g_mini/g_mini_backbone.py'\n",
            "adding 'keras_nlp/src/models/g_mini/g_mini_causal_lm.py'\n",
            "adding 'keras_nlp/src/models/g_mini/g_mini_causal_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/g_mini/g_mini_decoder_block.py'\n",
            "adding 'keras_nlp/src/models/g_mini/g_mini_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/g_mini/g_mini_presets.py'\n",
            "adding 'keras_nlp/src/models/g_mini/g_mini_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/g_mini/rms_normalization.py'\n",
            "adding 'keras_nlp/src/models/gpt2/__init__.py'\n",
            "adding 'keras_nlp/src/models/gpt2/gpt2_backbone.py'\n",
            "adding 'keras_nlp/src/models/gpt2/gpt2_causal_lm.py'\n",
            "adding 'keras_nlp/src/models/gpt2/gpt2_causal_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/gpt2/gpt2_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/gpt2/gpt2_presets.py'\n",
            "adding 'keras_nlp/src/models/gpt2/gpt2_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/gpt_neo_x/__init__.py'\n",
            "adding 'keras_nlp/src/models/gpt_neo_x/gpt_neo_x_attention.py'\n",
            "adding 'keras_nlp/src/models/gpt_neo_x/gpt_neo_x_backbone.py'\n",
            "adding 'keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm.py'\n",
            "adding 'keras_nlp/src/models/gpt_neo_x/gpt_neo_x_causal_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/gpt_neo_x/gpt_neo_x_decoder.py'\n",
            "adding 'keras_nlp/src/models/gpt_neo_x/gpt_neo_x_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/gpt_neo_x/gpt_neo_x_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/llama/__init__.py'\n",
            "adding 'keras_nlp/src/models/llama/llama_attention.py'\n",
            "adding 'keras_nlp/src/models/llama/llama_backbone.py'\n",
            "adding 'keras_nlp/src/models/llama/llama_decoder.py'\n",
            "adding 'keras_nlp/src/models/llama/llama_layernorm.py'\n",
            "adding 'keras_nlp/src/models/llama/llama_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/mistral/__init__.py'\n",
            "adding 'keras_nlp/src/models/mistral/mistral_attention.py'\n",
            "adding 'keras_nlp/src/models/mistral/mistral_backbone.py'\n",
            "adding 'keras_nlp/src/models/mistral/mistral_layer_norm.py'\n",
            "adding 'keras_nlp/src/models/mistral/mistral_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/mistral/mistral_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/mistral/mistral_transformer_decoder.py'\n",
            "adding 'keras_nlp/src/models/opt/__init__.py'\n",
            "adding 'keras_nlp/src/models/opt/opt_backbone.py'\n",
            "adding 'keras_nlp/src/models/opt/opt_causal_lm.py'\n",
            "adding 'keras_nlp/src/models/opt/opt_causal_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/opt/opt_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/opt/opt_presets.py'\n",
            "adding 'keras_nlp/src/models/opt/opt_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/roberta/__init__.py'\n",
            "adding 'keras_nlp/src/models/roberta/roberta_backbone.py'\n",
            "adding 'keras_nlp/src/models/roberta/roberta_classifier.py'\n",
            "adding 'keras_nlp/src/models/roberta/roberta_masked_lm.py'\n",
            "adding 'keras_nlp/src/models/roberta/roberta_masked_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/roberta/roberta_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/roberta/roberta_presets.py'\n",
            "adding 'keras_nlp/src/models/roberta/roberta_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/t5/__init__.py'\n",
            "adding 'keras_nlp/src/models/t5/t5_backbone.py'\n",
            "adding 'keras_nlp/src/models/t5/t5_layer_norm.py'\n",
            "adding 'keras_nlp/src/models/t5/t5_multi_head_attention.py'\n",
            "adding 'keras_nlp/src/models/t5/t5_presets.py'\n",
            "adding 'keras_nlp/src/models/t5/t5_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/t5/t5_transformer_layer.py'\n",
            "adding 'keras_nlp/src/models/whisper/__init__.py'\n",
            "adding 'keras_nlp/src/models/whisper/whisper_audio_feature_extractor.py'\n",
            "adding 'keras_nlp/src/models/whisper/whisper_backbone.py'\n",
            "adding 'keras_nlp/src/models/whisper/whisper_cached_multi_head_attention.py'\n",
            "adding 'keras_nlp/src/models/whisper/whisper_decoder.py'\n",
            "adding 'keras_nlp/src/models/whisper/whisper_encoder.py'\n",
            "adding 'keras_nlp/src/models/whisper/whisper_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/whisper/whisper_presets.py'\n",
            "adding 'keras_nlp/src/models/whisper/whisper_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/xlm_roberta/__init__.py'\n",
            "adding 'keras_nlp/src/models/xlm_roberta/xlm_roberta_backbone.py'\n",
            "adding 'keras_nlp/src/models/xlm_roberta/xlm_roberta_classifier.py'\n",
            "adding 'keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm.py'\n",
            "adding 'keras_nlp/src/models/xlm_roberta/xlm_roberta_masked_lm_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/xlm_roberta/xlm_roberta_preprocessor.py'\n",
            "adding 'keras_nlp/src/models/xlm_roberta/xlm_roberta_presets.py'\n",
            "adding 'keras_nlp/src/models/xlm_roberta/xlm_roberta_tokenizer.py'\n",
            "adding 'keras_nlp/src/models/xlnet/__init__.py'\n",
            "adding 'keras_nlp/src/models/xlnet/relative_attention.py'\n",
            "adding 'keras_nlp/src/models/xlnet/xlnet_backbone.py'\n",
            "adding 'keras_nlp/src/models/xlnet/xlnet_content_and_query_embedding.py'\n",
            "adding 'keras_nlp/src/models/xlnet/xlnet_encoder.py'\n",
            "adding 'keras_nlp/src/samplers/__init__.py'\n",
            "adding 'keras_nlp/src/samplers/beam_sampler.py'\n",
            "adding 'keras_nlp/src/samplers/contrastive_sampler.py'\n",
            "adding 'keras_nlp/src/samplers/greedy_sampler.py'\n",
            "adding 'keras_nlp/src/samplers/random_sampler.py'\n",
            "adding 'keras_nlp/src/samplers/sampler.py'\n",
            "adding 'keras_nlp/src/samplers/serialization.py'\n",
            "adding 'keras_nlp/src/samplers/top_k_sampler.py'\n",
            "adding 'keras_nlp/src/samplers/top_p_sampler.py'\n",
            "adding 'keras_nlp/src/tests/__init__.py'\n",
            "adding 'keras_nlp/src/tests/test_case.py'\n",
            "adding 'keras_nlp/src/tokenizers/__init__.py'\n",
            "adding 'keras_nlp/src/tokenizers/byte_pair_tokenizer.py'\n",
            "adding 'keras_nlp/src/tokenizers/byte_tokenizer.py'\n",
            "adding 'keras_nlp/src/tokenizers/sentence_piece_tokenizer.py'\n",
            "adding 'keras_nlp/src/tokenizers/sentence_piece_tokenizer_trainer.py'\n",
            "adding 'keras_nlp/src/tokenizers/tokenizer.py'\n",
            "adding 'keras_nlp/src/tokenizers/unicode_codepoint_tokenizer.py'\n",
            "adding 'keras_nlp/src/tokenizers/word_piece_tokenizer.py'\n",
            "adding 'keras_nlp/src/tokenizers/word_piece_tokenizer_trainer.py'\n",
            "adding 'keras_nlp/src/utils/__init__.py'\n",
            "adding 'keras_nlp/src/utils/keras_utils.py'\n",
            "adding 'keras_nlp/src/utils/pipeline_model.py'\n",
            "adding 'keras_nlp/src/utils/preset_utils.py'\n",
            "adding 'keras_nlp/src/utils/python_utils.py'\n",
            "adding 'keras_nlp/src/utils/tensor_utils.py'\n",
            "adding 'keras_nlp/tokenizers/__init__.py'\n",
            "adding 'keras_nlp-0.7.0.dist-info/METADATA'\n",
            "adding 'keras_nlp-0.7.0.dist-info/WHEEL'\n",
            "adding 'keras_nlp-0.7.0.dist-info/top_level.txt'\n",
            "adding 'keras_nlp-0.7.0.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[1m\u001b[92mSuccessfully built \u001b[4mkeras-nlp-0.7.0.tar.gz\u001b[0m\u001b[1m\u001b[92m and \u001b[4mkeras_nlp-0.7.0-py3-none-any.whl\u001b[0m\u001b[1m\u001b[92m\u001b[0m\n",
            "Build successful. Wheel file available at /content/keras-nlp-g-mini/dist/keras_nlp-0.7.0-py3-none-any.whl\n",
            "Installing wheel file.\n",
            "Processing ./dist/keras_nlp-0.7.0-py3-none-any.whl\n",
            "Installing collected packages: keras-nlp\n",
            "  Attempting uninstall: keras-nlp\n",
            "    Found existing installation: keras-nlp 0.7.0\n",
            "    Uninstalling keras-nlp-0.7.0:\n",
            "      Successfully uninstalled keras-nlp-0.7.0\n",
            "Successfully installed keras-nlp-0.7.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U keras>=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUpXCigbfDAA"
      },
      "source": [
        "Set the Keras backend. This tutorial uses PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn5uy8X8sdD0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # Or \"jax\" or \"tensorflow\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T7xe_jzslv4"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "Use [TensorFlow Datasets (TFDS)](https://www.tensorflow.org/datasets/overview) to load the IMDb dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiS-KU9osh_N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0328333d28764957b56509db242806aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c3f2483c43449a3b37476a5ad37b18d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5379d5580a5b4cf3bdea2e44e0e17ce2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12d80583f04f41b687ebfc3cee42e9c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b030bcc8546c4404a637a2482386ab49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteCPFHXV/imdb_reviews-train.tfrecord…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f481eb079ab4b15ae8ed9fecfeeb099",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c118ea15c40f4d468963ff9fd442b5cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteCPFHXV/imdb_reviews-test.tfrecord*…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ff8957040fb483c88e2216c9d12c16b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df794a11aaef4508ac02f3fd2715fad0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteCPFHXV/imdb_reviews-unsupervised.t…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\">"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "imdb_train = tfds.load(\n",
        "    \"imdb_reviews\",\n",
        "    split=\"train\",\n",
        "    as_supervised=True,\n",
        "    batch_size=2,\n",
        ")\n",
        "# Drop labels.\n",
        "imdb_train = imdb_train.map(lambda x, y: x)\n",
        "\n",
        "imdb_train.unbatch().take(1).get_single_element()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U-JS5L0fZCX"
      },
      "source": [
        "Use a subset of the dataset for faster training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq74R0Xl6YS3"
      },
      "outputs": [],
      "source": [
        "imdb_train = imdb_train.take(2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwwg4EpkswdD"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz5zLEyLstfn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/g_mini/keras/g_mini_2b_en/2/download/config.json...\n",
            "100%|██████████| 557/557 [00:00<00:00, 1.22MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/g_mini/keras/g_mini_2b_en/2/download/model.weights.h5...\n",
            "100%|██████████| 9.34G/9.34G [02:12<00:00, 75.7MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/g_mini/keras/g_mini_2b_en/2/download/tokenizer.json...\n",
            "100%|██████████| 404/404 [00:00<00:00, 925kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/g_mini/keras/g_mini_2b_en/2/download/assets/tokenizer/vocabulary.spm...\n",
            "100%|██████████| 4.04M/4.04M [00:00<00:00, 16.1MB/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"g_mini_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mPreprocessor: \"g_mini_causal_lm_preprocessor\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ g_mini_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GMiniTokenizer</span>)                  │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ g_mini_tokenizer (\u001b[38;5;33mGMiniTokenizer\u001b[0m)                  │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"g_mini_causal_lm\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"g_mini_causal_lm\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to                   </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ g_mini_backbone               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,434,…</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GMiniBackbone</span>)               │                           │             │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256128</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">524,550,144</span> │ g_mini_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │             │                                │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to                  \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ g_mini_backbone               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │ \u001b[38;5;34m2,506,434,…\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
              "│ (\u001b[38;5;33mGMiniBackbone\u001b[0m)               │                           │             │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256128\u001b[0m)      │ \u001b[38;5;34m524,550,144\u001b[0m │ g_mini_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │             │                                │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,434,560</span> (9.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,434,560\u001b[0m (9.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,434,560</span> (9.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,434,560\u001b[0m (9.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "\n",
        "g_mini_lm = keras_nlp.models.GMiniCausalLM.from_preset(\"g_mini_2b_en\")\n",
        "g_mini_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_L6A5J-1QgC"
      },
      "source": [
        "### Inference before fine tuning\n",
        "\n",
        "Prompt the model with a movie name (Modern Times) to generate responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwQz3xxxKciD"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Modern times 2022 is a year in which the world is facing a lot of changes. The most significant changes are taking place in the field of technology. The use of new and advanced technologies is becoming more and more prevalent in various areas, from healthcare to education.\\n\\nThe use of technology in healthcare'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g_mini_lm.generate(\"Modern times \", max_length=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85zCVtOIfvxN"
      },
      "source": [
        "The model generates some text but it is not related to a movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt7Nr6a7tItO"
      },
      "source": [
        "## LoRA Fine-tuning\n",
        "\n",
        "In this section, you will perform LoRA fine-tuning on the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCucu6oHz53G"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"g_mini_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mPreprocessor: \"g_mini_causal_lm_preprocessor\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ g_mini_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GMiniTokenizer</span>)                  │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ g_mini_tokenizer (\u001b[38;5;33mGMiniTokenizer\u001b[0m)                  │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"g_mini_causal_lm\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"g_mini_causal_lm\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to                   </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ g_mini_backbone               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,798,…</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GMiniBackbone</span>)               │                           │             │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256128</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">524,550,144</span> │ g_mini_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │             │                                │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to                  \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ g_mini_backbone               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │ \u001b[38;5;34m2,507,798,…\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
              "│ (\u001b[38;5;33mGMiniBackbone\u001b[0m)               │                           │             │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256128\u001b[0m)      │ \u001b[38;5;34m524,550,144\u001b[0m │ g_mini_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │             │                                │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,798,528</span> (9.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,798,528\u001b[0m (9.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,434,560</span> (9.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,434,560\u001b[0m (9.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Enable LoRA for the model and set the LoRA rank to 4.\n",
        "g_mini_lm.backbone.enable_lora(rank=4)\n",
        "g_mini_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQQ47kcdpbZ9"
      },
      "source": [
        "Note that enabling LoRA reduces the number of trainable parameters significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Peq7TnLtHse"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1642s\u001b[0m 820ms/step - loss: 2.9327 - sparse_categorical_accuracy: 0.4073\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d01b1b332e0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fine-tune on IMDb movie reviews.\n",
        "\n",
        "# Limit the input sequence length to 128 (to control memory usage).\n",
        "g_mini_lm.preprocessor.sequence_length = 128\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "g_mini_lm.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "g_mini_lm.fit(imdb_train, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yd-1cNw1dTn"
      },
      "source": [
        "### Inference after fine tuning\n",
        "After fine tuning the model, the generated text is related to the movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzSfMu7XipgN"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Modern times 1970s. A group of young friends decide to take revenge on their high school bully. They plan an elaborate revenge on their bully. They decide to kidnap him and take him to the woods. They plan to shoot him to death and make it look like a suicide. But they are'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g_mini_lm.generate(\"Modern times \", max_length=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSsRdeiof_rJ"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This tutorial walks you through using Keras NLP to fine-tune a G_mini model on the IMDb dataset."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lora_tuning.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
