{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "headers"
      },
      "source": [
        "Project: /_project.yaml\n",
        "Book: /_book.yaml\n",
        "\n",
        "<link rel=\"stylesheet\" href=\"/site-assets/css/style.css\">\n",
        "\n",
        "<!-- DO NOT EDIT! Automatically generated file. -->\n",
        "\n",
        "\n",
        "{% comment %}\n",
        "The source of truth file can be found [here]: http://google3/third_party/py/google/generativeai/site/en\n",
        "{% endcomment %}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# PaLM API: Quickstart with Curl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://developers.generativeai.google/tutorials/curl_quickstart\"><img src=\"https://developers.generativeai.google/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on Generative AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/curl_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/curl_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp_CKyzxUqx6"
      },
      "source": [
        "If you want to quickly try out the API, you can\n",
        "use curl commands to call the methods in the REST API. The following examples\n",
        "show calls for each API method. For each curl command, you must specify\n",
        "the model name and your API key. See the [get an API key](https://developers.generativeai.google/tutorials/setup)\n",
        "page if you don't already have one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2dk6P3nJz6m"
      },
      "source": [
        "## Generate text\n",
        "\n",
        "Use the [`generate_text`](https://developers.generativeai.google/api/rest/generativelanguage/models/generateText) method\n",
        "to generate a response from the model given an input message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niGIoHD5UWfI"
      },
      "outputs": [],
      "source": [
        "!curl https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001:generateText?key=$PALM_API_KEY \\\n",
        "    -H 'Content-Type: application/json' \\\n",
        "    -X POST \\\n",
        "    -d '{ \\\n",
        "        \"prompt\": { \\\n",
        "              \"text\": \"Write a story about a magic backpack.\" \\\n",
        "              } \\\n",
        "          }'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OvvPDyVvb4X"
      },
      "source": [
        "The following example specifies values for all the parameters of\n",
        "the [`generate_text`](https://developers.generativeai.google/api/rest/generativelanguage/models/generateText) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi_sU517UTxj"
      },
      "outputs": [],
      "source": [
        "curl https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001:generateText?key=$PALM_API_KEY \\\n",
        "        -H 'Content-Type: application/json' \\\n",
        "        -X POST \\\n",
        "        -d '{ \\\n",
        "            \"prompt\": { \\\n",
        "                  \"text\": \"Give an example of a title for a story about a magic backpack.  \\\n",
        "                           Title: \" \\\n",
        "                  }, \\\n",
        "            \"safetySettings\": [ \\\n",
        "                { \\\n",
        "                    \"category\": \"HARM_CATEGORY_TOXICITY\", \\\n",
        "                    \"threshold\": \"BLOCK_ONLY_HIGH\" \\\n",
        "                } \\\n",
        "            ], \\\n",
        "            \"stopSequences\": [ \\\n",
        "                \"Title\" \\\n",
        "            ], \\\n",
        "            \"temperature\": 1.0, \\\n",
        "            \"candidate_count\": 3, \\\n",
        "            \"maxOutputTokens\": 800, \\\n",
        "            \"topP\": 0.8, \\\n",
        "            \"topK\": 10 \\\n",
        "            }'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQFbvSfHQkix"
      },
      "source": [
        "The parameter values have the following meaning:\n",
        "\n",
        "* `safetySettings`: Lower the safety threshold for toxicity to only block highly probable toxic\n",
        "    outputs\n",
        "* `stopSequence`: Use the stop sequence to generate only 1 title by stopping the output at the\n",
        "    next instance of `Title`.\n",
        "* `temperature`: Set the temperature to 1.0 when generating responses.\n",
        "* `candidate_count`: Return only 3 candidate responses.\n",
        "* `maxOutputTokens`: Return a maximum of 800 tokens.\n",
        "* `topP`: Consider only the top 80% of the tokens returned by the model.\n",
        "* `topK`: Consider the top 10 tokens when sampling.\n",
        "\n",
        "Learn more about these parameters in the API reference\n",
        "for the [`generateText`](https://developers.generativeai.google/api/rest/generativelanguage/models/generateText#request-body)\n",
        "method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eca9b28591a"
      },
      "source": [
        "## Generate message\n",
        "\n",
        "Use the [`generateMessage`](https://developers.generativeai.google/api/rest/generativelanguage/models/generateMessage)\n",
        "method to generate a response from the model\n",
        "given an input [`MessagePrompt`](https://developers.generativeai.google/api/rest/generativelanguage/MessagePrompt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtBrAsv4R6FZ"
      },
      "outputs": [],
      "source": [
        "!curl https://generativelanguage.googleapis.com/v1beta2/models/chat-bison-001:generateMessage?key=$PALM_API_KEY  \\\n",
        "  -H 'Content-Type: application/json' \\\n",
        "  -X POST \\\n",
        "  -d '{ \\\n",
        "      \"prompt\": {\"messages\": [{\"content\":\"hi\"}] \\\n",
        "      }'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dede032595a0"
      },
      "source": [
        "The following example shows a call with different values for the parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecc8e5092861"
      },
      "outputs": [],
      "source": [
        "!curl  -H 'Content-Type: application/json' \\\n",
        "        -X POST \\\n",
        "        https://generativelanguage.googleapis.com/v1beta2/models/chat-bison-001:generateMessage?key=$PALM_API_KEY  \\\n",
        "        -d '{ \\\n",
        "            \"prompt\": {\"messages\": [{\"content\":\"hi\"}]}, \\\n",
        "            \"temperature\": 0.1, \\\n",
        "            \"candidate_count\": 1, \\\n",
        "            \"topP\": 0.8, \\\n",
        "            \"topK\": 10}' \\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvjt7eGlS91j"
      },
      "source": [
        "The parameter values have the following meaning:\n",
        "\n",
        "* `temperature`: Set the temperature to 0.1 when generating responses.\n",
        "* `candidate_count`: Return only 1 candidate response.\n",
        "* `topP`: Consider only the top 80% of the tokens returned by the model.\n",
        "* `topK`: Consider the top 10 tokens when sampling.\n",
        "\n",
        "Learn more about these parameters in the API reference\n",
        "for the [`generateMessage`](https://developers.generativeai.google/api/rest/generativelanguage/models/generateMessage#request-body)\n",
        "method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUnLAdvWTLWs"
      },
      "source": [
        "## Embed text\n",
        "\n",
        "Use the [`embedText`](https://developers.generativeai.google/api/rest/generativelanguage/models/embedText) method to\n",
        "generate an embedding from the model given an input message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n15MvK5gT-Ln"
      },
      "outputs": [],
      "source": [
        "!curl https://generativelanguage.googleapis.com/v1beta2/models/embedding-gecko-001:embedText?key=$PALM_API_KEY \\\n",
        "  -H 'Content-Type: application/json' \\\n",
        "  -X POST \\\n",
        "  -d '{\"text\": \"say something nice!\"}'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnC8X8dTxbZ"
      },
      "source": [
        "## Count message tokens\n",
        "\n",
        "Use the\n",
        "[`countMessageTokens`](https://developers.generativeai.google/api/rest/generativelanguage/models/countMessageTokens)\n",
        "method to run a model's tokenizer on a message\n",
        "prompt string and get a token count.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKsS8UQoTx6V"
      },
      "outputs": [],
      "source": [
        "!curl https://generativelanguage.googleapis.com/v1beta2/models/chat-bison-001:countMessageTokens?key=$PALM_API_KEY \\\n",
        "    -H 'Content-Type: application/json' \\\n",
        "    -X POST \\\n",
        "    -d '{ \\\n",
        "        \"prompt\": { \\\n",
        "            \"messages\": [ \\\n",
        "                {\"content\":\"How many tokens?\"}, \\\n",
        "                {\"content\":\"For this whole conversation?\"} \\\n",
        "            ] \\\n",
        "        } \\\n",
        "    }'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5YvjjSlTm3z"
      },
      "source": [
        "## Get model\n",
        "\n",
        "Use the [`get`](https://developers.generativeai.google/api/rest/generativelanguage/models/get) method to get information about a specific model such as\n",
        "version, display name, input token limit, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QFyHo12Tmoz"
      },
      "outputs": [],
      "source": [
        "!curl https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001?key=$PALM_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMrW8_JyThOc"
      },
      "source": [
        "## List models\n",
        "\n",
        "Use the [`list`](https://developers.generativeai.google/api/rest/generativelanguage/models/list) method to list all of the models available through the\n",
        "PaLM API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVcag-ARTckt"
      },
      "outputs": [],
      "source": [
        "!curl https://generativelanguage.googleapis.com/v1beta2/models?key=$PALM_API_KEY"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "curl_quickstart.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}